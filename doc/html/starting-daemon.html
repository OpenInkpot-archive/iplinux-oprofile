<HTML
><HEAD
><TITLE
>Starting profiling</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.54"><LINK
REL="HOME"
TITLE="OProfile manual"
HREF="oprofile-guide.html"><LINK
REL="UP"
TITLE="Usage"
HREF="usage.html"><LINK
REL="PREVIOUS"
TITLE="Usage"
HREF="usage.html"><LINK
REL="NEXT"
TITLE="Other features"
HREF="features.html"></HEAD
><BODY
CLASS="SECT1"
><DIV
CLASS="NAVHEADER"
><TABLE
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="3"
ALIGN="center"
>OProfile manual</TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="bottom"
><A
HREF="usage.html"
>Prev</A
></TD
><TD
WIDTH="80%"
ALIGN="center"
VALIGN="bottom"
>Chapter 2. Usage</TD
><TD
WIDTH="10%"
ALIGN="right"
VALIGN="bottom"
><A
HREF="features.html"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="STARTING-DAEMON"
>Starting profiling</A
></H1
><P
>In this section the configuration and startup of the profiler is discussed in more depth. </P
><P
>A shell script <B
CLASS="COMMAND"
>op_start</B
> is provided to set up the correct environment, insert the kernel module,
and start up the profiler daemon. It is recommended that you use this script to start profiling, though you can
do it yourself by hand if you want (just see the shell script for how things need setting up). OProfile stores
its relevant files in <TT
CLASS="FILENAME"
>/var/opd</TT
> by default. Of most interest are the <TT
CLASS="FILENAME"
>oprofiled.log</TT
>
log file, and the <TT
CLASS="FILENAME"
>samples/</TT
> directory. The <TT
CLASS="FILENAME"
>samples</TT
> directory
contains the actual sample profile files created by the daemon. Despite their apparent size they take up
much less actual diskspace as they are created sparsely (<B
CLASS="COMMAND"
>stat</B
> should tell you their real
on-disk size). Each filename corresponds to the profiled binary image (with <TT
CLASS="CONSTANT"
>/</TT
> characters
replaced with <TT
CLASS="CONSTANT"
>}</TT
> characters). The man page for <B
CLASS="COMMAND"
>op_start</B
> details the
all the options, only interesting ones are listed here :</P
><P
> 
<P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><TT
CLASS="OPTION"
>--list-events</TT
></DT
><DD
><P
>		This gives a short list of the hardware events that are countable (see <A
HREF="starting-daemon.html#HARDWARE-COUNTERS"
>the section called <I
>Intel P6 Performance Counters</I
></A
>).
		The meaning of options relating to the counters themselves is also detailed in that section.
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--buffer-size</TT
></DT
><DD
><P
>		This is the number of entries in the kernel-side profiling buffer. Generally the default value
		is fine: you might want to change this on low-memory machines, or if you are doing very detailed profiling.
		Each entry in the buffer takes 8 bytes. 
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--hash-table-size</TT
></DT
><DD
><P
>		This is the number of entries in the kernel-side profiling hash table. Generally the default value
		is fine: you might want to change this on low-memory machines, or if you are doing very detailed profiling.
		Each entry in the hash table takes 32 bytes (4 samples for each entry).
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--kernel-only</TT
></DT
><DD
><P
>		Default is to profile both user-space and the kernel. You can profile only the kernel with this option;
		this does not prevent the occasional user-space sample due to the hardware constraints, but reduces the
		overhead considerably.
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--map-file</TT
></DT
><DD
><P
>		Specify the <TT
CLASS="FILENAME"
>System.map</TT
> file from the current kernel's compile. This must match
		the running kernel if you expect meaningful profiles of the kernel.
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--vmlinux</TT
></DT
><DD
><P
>		Specify the <TT
CLASS="FILENAME"
>vmlinux</TT
> file from the current kernel's compile. This must match
		the running kernel if you expect meaningful profiles of the kernel.
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--use-cpu</TT
></DT
><DD
><P
>		Specify 0 for Pentium Pros, 1 for Pentium II and 2 for Pentium III. This is only needed if you use
		an event not available on the Pentium Pro. 
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--pid-filter</TT
></DT
><DD
><P
>		If you compiled with the <TT
CLASS="OPTION"
>--enable-filter</TT
> option, you can specify a process id here. Only
		samples of this process id will be collected (including any kernel-side samples when this process is in
		the kernel). Note that threaded programs under Linux have a different process id for each thread.
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--pgrp-filter</TT
></DT
><DD
><P
>		If you compiled with the <TT
CLASS="OPTION"
>--enable-filter</TT
> option, you can specify a process group id here. Only
		samples of this process group id will be collected (including any kernel-side samples when this process is in
		the kernel).
		</P
></DD
><DT
><TT
CLASS="OPTION"
>--verbose</TT
></DT
><DD
><P
>		This makes the daemon <I
CLASS="EMPHASIS"
>very</I
> verbose in its logfile. Don't use this unless you need it
		as the overhead of logging the data is significant. It is however useful for determining profiler bugs
		(believe me ;) 
		</P
></DD
></DL
></DIV
></P
><P
> 
As mentioned, the runtime profiler system consists of two components: a kernel module (<TT
CLASS="FILENAME"
>oprofile</TT
>)
and a user-space daemon process (<TT
CLASS="FILENAME"
>oprofiled</TT
>). The kernel module collects sample data into
the hash table and buffer, and wakes up the daemon process when it is approaching full. The daemon will read this
data, and process it into a non-volatile form. Any samples are recorded into the sample files at processing time. </P
><P
>The <B
CLASS="COMMAND"
>op_start</B
> shell script will insert the kernel module if needed. Once inserted, it cannot
be removed (although it can be de-activated, freeing almost all memory used during profiling). The profiling
is activated when the daemon process initialises. Configuration of the kernel module parameters is done
via <B
CLASS="COMMAND"
>sysctl</B
>; the available files are detailed in <A
HREF="starting-daemon.html#SYSCTL"
>the section called <I
><B
CLASS="COMMAND"
>sysctl</B
> tree</I
></A
>.</P
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="HARDWARE-COUNTERS"
>Intel P6 Performance Counters</A
></H2
><P
>The hardware performance counters are detailed in the Intel IA-32 Architecture Manual, Volume 3, available
from <A
HREF="http://developer.intel.com/"
TARGET="_top"
>http://developer.intel.com/</A
>. P6-core processors are capable
of delivering an interrupt to the local <SPAN
CLASS="ACRONYM"
>APIC</SPAN
> <SPAN
CLASS="ACRONYM"
>LVTPC</SPAN
> vector
when a counter overflows. This is the basic mechanism on which OProfile is based. The kernel module
installs an interrupt handler for this vector. The delivery mode is set to <SPAN
CLASS="ACRONYM"
>NMI</SPAN
> so that
blocking interrupts in the kernel does not prevent profiling. When the interrupt handler is called,
the current <SPAN
CLASS="ACRONYM"
>EIP</SPAN
> <SPAN
CLASS="ACRONYM"
>PC</SPAN
> value, process id, and counter (there are only
two counters, 0 and 1) are recorded into the profiling structure. This allows the overflow event to be attached
to a specific assembly instruction in a binary image. The daemon is necessary to transform these recorded 
values into a count against a file offset for a given binary image, in order to produce profile data off-line
at a later time. </P
><P
>If we use an event such as <TT
CLASS="CONSTANT"
>CPU_CLK_UNHALTED</TT
> or <TT
CLASS="CONSTANT"
>INST_RETIRED</TT
>, we can
use the overflow counts as an estimate of actual time spent in each part of code. Alternatively we can
profile interesting data such as the cache behaviour of routines with the other available counters.</P
><P
>However there are several caveats. Firstly there are those issues listed in the Intel manual. There is a delay
between the counter overflow and the interrupt delivery that can skew results on a small scale - this means
you cannot rely on the profiles at the instruction level, except as a binary was/wasn't executed indicator. 
If you are using an "event-mode" counter such as the cache counters, a count registered against it doesn't mean 
that it is responsible for that event. However, it implies that the counter overflowed in the dynamic
vicinity of that instruction, to within a few instructions. Further details on this problem can be found in
the Digital paper "ProfileMe: A Hardware Performance Counter". Also note that a very high number of interrupts
can have a large performance effect, and even overflow the profiling data structures. This can lead to mapping information
getting overwritten, and loss of respect from boxing promoter (don't worry, an obscure reference). The system
stability will never be affected, but profiling may not be able to work properly. An error message from the
kernel module will appear in your system log files if this situation occurs.</P
><P
>As described in the Intel manual, each counter, as well as being configured to count an event type, has several
more configuration parameters. First, there is the unit mask: this simply further specifies what to count.
Second, there is the counter value, discussed below. Third, there is a parameter whether to increment counts
whilst in kernel or user space. You can configure these separately for each counter.</P
><P
>So you must specify a counter value with the <TT
CLASS="OPTION"
>--ctrX-count</TT
> option, where <TT
CLASS="OPTION"
>X</TT
>
is either 0 or 1 for which counter to program. After each overflow event, the counter will be re-initialised
such that another overflow will occur after this many events have been counted. Picking a good value for this
parameter is, unfortunately, somewhat of a grey art (not quite black). It is of course dependent on the event
you have chosen. For basic time-based profiling, you will probably use <TT
CLASS="CONSTANT"
>CPU_CLK_UNHALTED</TT
>.
You can estimate how many interrupts this value will generate per second with this event by dividing your CPU
clock rate by the chosen value. I have a 600MHz Celeron, so specifying an overflow value of 100,000 will generate
around 600 interrupts per second. Specifying too large a value will mean not enough interrupts are generated
to give a realistic profile (though this problem can be ameliorated by profiling for <I
CLASS="EMPHASIS"
>longer</I
>).
Specifying too small a value can lead to overflow problems discussed previously.</P
></DIV
><DIV
CLASS="SECT2"
><H2
CLASS="SECT2"
><A
NAME="SYSCTL"
><B
CLASS="COMMAND"
>sysctl</B
> tree</A
></H2
><P
>When the kernel module loads, it generates a file hierarchy underneath <TT
CLASS="FILENAME"
>/proc/sys/dev/oprofile</TT
>.
You can read and write to these files to give direct access to the kernel parameters.
<DIV
CLASS="NOTE"
><BLOCKQUOTE
CLASS="NOTE"
><P
><B
>Note: </B
>With the exception of <TT
CLASS="FILENAME"
>dump</TT
>, any changes only take effect on restarting the profiler.</P
></BLOCKQUOTE
></DIV
>
The following files will be present :
<P
></P
><DIV
CLASS="VARIABLELIST"
><DL
><DT
><TT
CLASS="FILENAME"
>bufsize</TT
></DT
><DD
><P
>		The buffer size, corresponding to the <TT
CLASS="OPTION"
>--buffer-size</TT
> option. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>hashsize</TT
></DT
><DD
><P
>		The hash table size, corresponding to the <TT
CLASS="OPTION"
>--hash-table-size</TT
> option. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>kernel_only</TT
></DT
><DD
><P
>		Corresponding to the <TT
CLASS="OPTION"
>--kernel-only</TT
> option. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>pgrp_filter</TT
></DT
><DD
><P
>		Corresponding to the <TT
CLASS="OPTION"
>--pgrp-filter</TT
> option. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>pid_filter</TT
></DT
><DD
><P
>		Corresponding to the <TT
CLASS="OPTION"
>--pid-filter</TT
> option. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>dump</TT
></DT
><DD
><P
>		Writing <SPAN
CLASS="ACRONYM"
>ASCII</SPAN
> "1" to the file will initiate a sample data dump. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>0, 1, ...</TT
></DT
><DD
><P
>		Each <SPAN
CLASS="ACRONYM"
>CPU</SPAN
> will have a directory containing two child directories,
		one for each counter. The rest of the files described here are per-counter. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>count</TT
></DT
><DD
><P
>		The counter value for this counter. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>enabled</TT
></DT
><DD
><P
>		Whether this counter is active. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>event</TT
></DT
><DD
><P
>		The numeric event value. You can convert from symbolic event names to numeric values like so :
		</P
><P
><B
CLASS="COMMAND"
>echo `op_help CPU_CLK_UNHALTED` &#62;/proc/sys/dev/oprofile/0/0/event</B
> 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>kernel</TT
></DT
><DD
><P
>		Whether to profile the kernel. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>unit_mask</TT
></DT
><DD
><P
>		The unit mask specified. 
		</P
></DD
><DT
><TT
CLASS="FILENAME"
>user</TT
></DT
><DD
><P
>		Whether to profile user-space. 
		</P
></DD
></DL
></DIV
> </P
></DIV
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="usage.html"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="oprofile-guide.html"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="features.html"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Usage</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="usage.html"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>Other features</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>